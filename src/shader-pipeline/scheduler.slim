@Internal
type TreeNode = struct {
    mask_t threads;
    u32 depth;
};

@Exported @Internal
type JoinPoint = struct {
    TreeNode node;
    fn_ptr_t destination;
    u32 payload;
};

// const u32 SpvScopeSubgroup = 3;
// const u32 SpvGroupOperationReduce = 0;
// const u32 OpGroupNonUniformElect = 333;
// const u32 OpGroupNonUniformBroadcastFirst = 338;
// const u32 OpGroupNonUniformBallot = 339;
// const u32 OpGroupNonUniformIAdd = 349;

@Internal var logical subgroup u32 actual_subgroup_size;

@Internal var logical subgroup u32 scheduler_cursor = 0;
@Internal var logical subgroup [TreeNode; SUBGROUP_SIZE] scheduler_vector;
@Exported @Internal var logical subgroup [fn_ptr_t; SUBGROUP_SIZE] resume_at;

@Exported @Internal var logical subgroup fn_ptr_t next_fn;
@Exported @Internal var logical subgroup TreeNode active_branch;

@Internal @Builtin("SubgroupLocalInvocationId")
var input u32 subgroup_local_id;

@Internal @Builtin("SubgroupId")
var uniform input u32 subgroup_id;

@Internal
fn subgroup_active_mask uniform mask_t() {
    return (ext_instr["spirv.core", 339, uniform mask_t](3, true));
}

@Internal
fn subgroup_ballot uniform mask_t(varying bool b) {
    return (ext_instr["spirv.core", 339, uniform mask_t](3, b));
}

@Internal @Exported
fn builtin_init_scheduler() {
    val init_mask = subgroup_active_mask();

    val tree_node1 = composite TreeNode(init_mask, 1);
    scheduler_vector#(subgroup_local_id) = tree_node1;
    active_branch = tree_node1;

    actual_subgroup_size = (ext_instr["spirv.core", 349, varying u32](3, u32 0, u32 1));
}

@Internal @Exported
fn builtin_entry_join_point uniform JoinPoint() {
    val init_mask = subgroup_active_mask();

    val tree_node0 = composite TreeNode(init_mask, 0);
    val jp = composite JoinPoint(tree_node0, 0, 0);
    return (jp);
}

@Internal @Exported
fn builtin_create_control_point varying JoinPoint(uniform fn_ptr_t join_destination, varying u32 payload) {
    val curr_mask = subgroup_active_mask();
    val depth = ext_instr["spirv.core", 338, uniform u32](3, scheduler_vector#(subgroup_local_id)#1);
    val tree_node = composite TreeNode(curr_mask, depth);
    val jp = composite JoinPoint(tree_node, join_destination, payload);

    // increase the depth of the active leaves
    scheduler_vector#(subgroup_local_id)#1 = scheduler_vector#(subgroup_local_id)#1 + u32 1;

    return (jp);
}

@Internal @Exported
fn builtin_fork(varying fn_ptr_t branch_destination) {
    val first_branch = ext_instr["spirv.core", 338, uniform fn_ptr_t](3, branch_destination);

    // if there is disagreement on the destination, then increase the depth of every branch
    val uniform_branch = subgroup_active_mask() == subgroup_ballot(first_branch == branch_destination);
    if (!uniform_branch) {
        // update depth counter
        val old_depth = scheduler_vector#(subgroup_local_id)#1;
        scheduler_vector#(subgroup_local_id)#1 = old_depth + u32 1;
    }

    // Partition the set of branch destinations and adapt the masks in turn
    loop() {
        val elected = ext_instr["spirv.core", 338, uniform fn_ptr_t](3, branch_destination);
        resume_at#(subgroup_local_id) = elected;
        scheduler_vector#(subgroup_local_id)#0 = subgroup_ballot(elected == branch_destination);
        if (elected == branch_destination) {
            break;
        }
    }

    // We must pick one branch as our 'favourite child' to schedule for immediate execution
    // we could do fancy intrinsics, but for now we'll just pick the first one
    if (ext_instr["spirv.core", 333, varying bool](3)) {
        next_fn = ext_instr["spirv.core", 338, uniform fn_ptr_t](3, branch_destination);
        active_branch = ext_instr["spirv.core", 338, uniform TreeNode](3, scheduler_vector#(subgroup_local_id));

        // tag those variables as not in use#
        // resume_at#(subgroup_local_id) = -1;
        // resume_with#(subgroup_local_id) = empty_mask();
        // return ();
    }
}

@Internal @Exported
fn builtin_jump(uniform fn_ptr_t branch_destination) {
    // Partition the set of branch destinations and adapt the masks in turn
    resume_at#(subgroup_local_id) = branch_destination;
    scheduler_vector#(subgroup_local_id)#0 = subgroup_ballot(true);

    next_fn = branch_destination;
    active_branch = ext_instr["spirv.core", 338, uniform TreeNode](3, scheduler_vector#(subgroup_local_id));
}

@Internal @Exported
fn builtin_yield(uniform fn_ptr_t resume_target) {
    resume_at#(subgroup_local_id) = resume_target;
    // resume_with#(subgroup_local_id) = subgroup_active_mask();

    // only one thread runs that part
    if (ext_instr["spirv.core", 333, varying bool](3)) {
        // bump the cursor
        // TODO bump it in a smarter way
        scheduler_cursor = (scheduler_cursor + u32 1) % actual_subgroup_size;
        builtin_find_schedulable_leaf();
    }
}

@Internal @Exported
fn builtin_join(varying fn_ptr_t join_at, varying TreeNode token) {
    resume_at#(subgroup_local_id) = join_at;
    scheduler_vector#(subgroup_local_id) = token;

    // only one thread runs that part
    if (ext_instr["spirv.core", 333, varying bool](3)) {
        builtin_find_schedulable_leaf();
    }
}

@Internal
fn is_parent bool(varying TreeNode child, varying TreeNode maybe_parent) {
  val child_mask = child#0;
  val parent_mask = maybe_parent#0;
  if ((child_mask | parent_mask) != parent_mask) { return(false); }
  val child_depth = child#1;
  val parent_depth = maybe_parent#1;
  return (child_depth >= parent_depth);
}

@Internal
fn forward_distance u32(varying u32 x, varying u32 dst, varying u32 max_mod) {
  var u32 t = dst - x;
  t = t % max_mod;
  return (t);
}

@Internal
fn reduce2 u32(varying u32 a_index, varying u32 b_index) {
    val a = scheduler_vector#a_index;
    val b = scheduler_vector#b_index;

    if (is_parent(a, b)) { return (a_index); }
    if (is_parent(b, a)) { return (b_index); }

    val a_dist = forward_distance(a_index, scheduler_cursor, actual_subgroup_size);
    val b_dist = forward_distance(b_index, scheduler_cursor, actual_subgroup_size);

    if (a_dist < b_dist) { return (a_index); }
    return (b_index);
}

@Internal
fn builtin_find_schedulable_leaf() {
    var u32 reduced = u32 0;
    loop (varying u32 i = u32 1) {
        if (i >= actual_subgroup_size) { break; }
        reduced = reduce2(reduced, i);
        continue(i + u32 1);
    }

    next_fn = ext_instr["spirv.core", 338, uniform fn_ptr_t](3, resume_at#reduced);
    active_branch = ext_instr["spirv.core", 338, uniform TreeNode](3, scheduler_vector#reduced);
    return ();
}

@Internal @Exported
fn builtin_get_active_threads_mask mask_t() {
    val this_thread_branch = scheduler_vector#(subgroup_local_id);
    val same_dest = resume_at#(subgroup_local_id) == next_fn;
    val not_escaping = is_parent(this_thread_branch, active_branch);
    return (subgroup_ballot(same_dest & not_escaping));
}
